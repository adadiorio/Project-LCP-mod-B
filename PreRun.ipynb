{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081c9555-d877-4796-b843-ae2fdcc2b29f",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c7d6d7-25ea-4630-976d-d3aeedc25853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "# Transformers libraries\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2LMHeadModel, GPT2Model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ec6cd-d163-46f2-8211-e4beff8ba012",
   "metadata": {},
   "source": [
    "### Definition of the model and the hook function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c49573-1d12-4ab2-812e-3d471bae6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'openai-community/gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, output_attentions=True)\n",
    "gpt2_model = model.transformer\n",
    "\n",
    "# Function to be called by the hook\n",
    "output_list, module_list = [], []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    output_list.append(output)\n",
    "    module_list.append(module)\n",
    "\n",
    "# Attaching hook to all layers\n",
    "for layer in model.modules():\n",
    "    layer.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5414660-e6ed-4a17-bab2-b9e3664401cc",
   "metadata": {},
   "source": [
    "### Choosing the prompt and running gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd223f1-d197-4583-b5fe-996b58c75950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "attn_output shape:  torch.Size([1, 308, 768])\n",
      "0 Embedding(50257, 768)    output_shape:  torch.Size([1, 308, 768])\n",
      "1 Embedding(1024, 768)    output_shape:  torch.Size([1, 308, 768])\n",
      "2 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "3 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "4 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "5 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "6 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "7 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "8 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "9 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "10 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "11 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "12 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "13 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "14 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "15 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "16 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "17 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "18 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "19 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "20 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "21 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "22 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "23 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "24 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "25 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "26 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "27 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "28 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "29 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "30 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "31 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "32 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "33 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "34 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "35 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "36 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "37 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "38 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "39 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "40 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "41 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "42 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "43 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "44 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "45 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "46 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "47 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "48 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "49 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "50 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "51 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "52 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "53 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "54 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "55 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "56 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "57 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "58 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "59 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "60 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "61 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "62 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "63 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "64 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "65 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "66 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "67 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "68 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "69 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "70 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "71 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "72 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "73 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "74 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "75 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "76 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "77 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "78 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "79 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "80 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "81 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "82 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "83 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "84 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "85 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "86 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "87 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "88 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "89 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "90 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "91 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "92 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "93 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "94 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "95 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "96 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "97 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "98 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "99 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "100 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "101 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "102 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "103 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "104 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "105 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "106 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "107 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "108 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "109 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "110 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "111 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "112 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "113 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "114 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "115 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "116 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "117 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "118 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "119 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "120 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "121 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "122 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "123 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "124 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "125 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "126 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "127 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "128 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "129 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "130 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "131 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "132 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "133 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "134 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "135 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "136 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "137 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "138 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "139 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "140 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "141 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "142 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "143 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "144 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "145 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "146 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "147 Conv1D()    output_shape:  torch.Size([1, 308, 2304])\n",
      "148 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 12, 308, 308])\n",
      "149 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "150 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "151 GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  3\n",
      "152 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "153 Conv1D()    output_shape:  torch.Size([1, 308, 3072])\n",
      "154 NewGELUActivation()    output_shape:  torch.Size([1, 308, 3072])\n",
      "155 Conv1D()    output_shape:  torch.Size([1, 308, 768])\n",
      "156 Dropout(p=0.1, inplace=False)    output_shape:  torch.Size([1, 308, 768])\n",
      "157 GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")    output_shape:  torch.Size([1, 308, 768])\n",
      "158 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")    output_shape:  3\n",
      "159 LayerNorm((768,), eps=1e-05, elementwise_affine=True)    output_shape:  torch.Size([1, 308, 768])\n",
      "160 GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")    output_shape:  3\n",
      "161 Linear(in_features=768, out_features=50257, bias=False)    output_shape:  torch.Size([1, 308, 50257])\n",
      "162 GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")    output_shape:  3\n"
     ]
    }
   ],
   "source": [
    "# About Walt Whitman (Tokens: 308)\n",
    "prompt = \"Explain this poem: O Captain! my Captain! our fearful trip is done,\\nThe ship has weather’d every rack, the prize we sought is won,\\nThe port is near, the bells I hear, the people all exulting,\\nWhile follow eyes the steady keel, the vessel grim and daring;\\nBut O heart! heart! heart!\\nO the bleeding drops of red,\\nWhere on the deck my Captain lies,\\nFallen cold and dead.\\n\\nO Captain! my Captain! rise up and hear the bells;\\nRise up—for you the flag is flung—for you the bugle trills,\\nFor you bouquets and ribbon’d wreaths—for you the shores a-crowding,\\nFor you they call, the swaying mass, their eager faces turning;\\nHere Captain! dear father!\\nThis arm beneath your head!\\nIt is some dream that on the deck,\\nYou’ve fallen cold and dead.\\n\\nMy Captain does not answer, his lips are pale and still,\\nMy father does not feel my arm, he has no pulse nor will,\\nThe ship is anchor’d safe and sound, its voyage closed and done,\\nFrom fearful trip the victor ship comes in with object won;\\nExult O shores, and ring O bells!\\nBut I with mournful tread,\\nWalk the deck my Captain lies,\\nFallen cold and dead.\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    \n",
    "for i, module in enumerate(module_list):\n",
    "    try:\n",
    "        print(i, module, '   output_shape: ', output_list[i].shape)\n",
    "    except:\n",
    "        try:\n",
    "            print(i, module, '   output_shape: ', len(output_list[i]))\n",
    "        except:\n",
    "            print(i, module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3c1e3-440c-4b47-8e3a-50f21382039f",
   "metadata": {},
   "source": [
    "### Storing output list and module list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa014679-d5c8-4f15-8515-8a5d2932adf1",
   "metadata": {},
   "source": [
    "#### Word2Vec conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca243823-0197-4dc2-9ebd-43d5bdae1f41",
   "metadata": {},
   "source": [
    "Remember that the passages are:\n",
    "    \n",
    "    1. Convert word to tokens and tokens to vectors\n",
    "    2. Apply the positional encoding matrix\n",
    "    3. Sum the positional encoding to the vectorial representation of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fade4264-e634-410c-9790-9c1ee67bbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token2Vec          = output_list[0][0]\n",
    "PositionalEncoding = output_list[1][0]\n",
    "PositionPlusVect   = output_list[2][0]\n",
    "\n",
    "torch.save(Token2Vec, \"output_Captain/word2vec/Token2Vec.pt\")\n",
    "torch.save(PositionalEncoding, \"output_Captain/word2vec/PositionalEncoding.pt\")\n",
    "torch.save(PositionPlusVect, \"output_Captain/word2vec/PositionPlusVect.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91101dad-6bd6-4fac-9a59-e50a543a1e89",
   "metadata": {},
   "source": [
    "#### Storing evolution of the decoder blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb4716d-1b2e-4916-9168-440441f0bb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder  1   FirstNormalization\n",
      "Decoder  1   QKV_representation\n",
      "Decoder  1   AttentionHeads\n",
      "Decoder  1   AttentionProj\n",
      "Decoder  1   SecondNormalization\n",
      "Decoder  1   FirstLayerNN\n",
      "Decoder  1   SecondLayerNN\n",
      "Decoder  1   Decoder_Final_Output\n",
      "Decoder  2   FirstNormalization\n",
      "Decoder  2   QKV_representation\n",
      "Decoder  2   AttentionHeads\n",
      "Decoder  2   AttentionProj\n",
      "Decoder  2   SecondNormalization\n",
      "Decoder  2   FirstLayerNN\n",
      "Decoder  2   SecondLayerNN\n",
      "Decoder  2   Decoder_Final_Output\n",
      "Decoder  3   FirstNormalization\n",
      "Decoder  3   QKV_representation\n",
      "Decoder  3   AttentionHeads\n",
      "Decoder  3   AttentionProj\n",
      "Decoder  3   SecondNormalization\n",
      "Decoder  3   FirstLayerNN\n",
      "Decoder  3   SecondLayerNN\n",
      "Decoder  3   Decoder_Final_Output\n",
      "Decoder  4   FirstNormalization\n",
      "Decoder  4   QKV_representation\n",
      "Decoder  4   AttentionHeads\n",
      "Decoder  4   AttentionProj\n",
      "Decoder  4   SecondNormalization\n",
      "Decoder  4   FirstLayerNN\n",
      "Decoder  4   SecondLayerNN\n",
      "Decoder  4   Decoder_Final_Output\n",
      "Decoder  5   FirstNormalization\n",
      "Decoder  5   QKV_representation\n",
      "Decoder  5   AttentionHeads\n",
      "Decoder  5   AttentionProj\n",
      "Decoder  5   SecondNormalization\n",
      "Decoder  5   FirstLayerNN\n",
      "Decoder  5   SecondLayerNN\n",
      "Decoder  5   Decoder_Final_Output\n",
      "Decoder  6   FirstNormalization\n",
      "Decoder  6   QKV_representation\n",
      "Decoder  6   AttentionHeads\n",
      "Decoder  6   AttentionProj\n",
      "Decoder  6   SecondNormalization\n",
      "Decoder  6   FirstLayerNN\n",
      "Decoder  6   SecondLayerNN\n",
      "Decoder  6   Decoder_Final_Output\n",
      "Decoder  7   FirstNormalization\n",
      "Decoder  7   QKV_representation\n",
      "Decoder  7   AttentionHeads\n",
      "Decoder  7   AttentionProj\n",
      "Decoder  7   SecondNormalization\n",
      "Decoder  7   FirstLayerNN\n",
      "Decoder  7   SecondLayerNN\n",
      "Decoder  7   Decoder_Final_Output\n",
      "Decoder  8   FirstNormalization\n",
      "Decoder  8   QKV_representation\n",
      "Decoder  8   AttentionHeads\n",
      "Decoder  8   AttentionProj\n",
      "Decoder  8   SecondNormalization\n",
      "Decoder  8   FirstLayerNN\n",
      "Decoder  8   SecondLayerNN\n",
      "Decoder  8   Decoder_Final_Output\n",
      "Decoder  9   FirstNormalization\n",
      "Decoder  9   QKV_representation\n",
      "Decoder  9   AttentionHeads\n",
      "Decoder  9   AttentionProj\n",
      "Decoder  9   SecondNormalization\n",
      "Decoder  9   FirstLayerNN\n",
      "Decoder  9   SecondLayerNN\n",
      "Decoder  9   Decoder_Final_Output\n",
      "Decoder  10   FirstNormalization\n",
      "Decoder  10   QKV_representation\n",
      "Decoder  10   AttentionHeads\n",
      "Decoder  10   AttentionProj\n",
      "Decoder  10   SecondNormalization\n",
      "Decoder  10   FirstLayerNN\n",
      "Decoder  10   SecondLayerNN\n",
      "Decoder  10   Decoder_Final_Output\n",
      "Decoder  11   FirstNormalization\n",
      "Decoder  11   QKV_representation\n",
      "Decoder  11   AttentionHeads\n",
      "Decoder  11   AttentionProj\n",
      "Decoder  11   SecondNormalization\n",
      "Decoder  11   FirstLayerNN\n",
      "Decoder  11   SecondLayerNN\n",
      "Decoder  11   Decoder_Final_Output\n",
      "Decoder  12   FirstNormalization\n",
      "Decoder  12   QKV_representation\n",
      "Decoder  12   AttentionHeads\n",
      "Decoder  12   AttentionProj\n",
      "Decoder  12   SecondNormalization\n",
      "Decoder  12   FirstLayerNN\n",
      "Decoder  12   SecondLayerNN\n",
      "Decoder  12   Decoder_Final_Output\n"
     ]
    }
   ],
   "source": [
    "index_list = np.array([3, 4, 5, 7, 9, 11, 13, 15])\n",
    "'''\n",
    "Decoder_01_FirstNormalization  = output_list[3]\n",
    "Decoder_01_QKV_representation  = output_list[4]\n",
    "Decoder_01_AttentionHeads      = output_list[5]\n",
    "Decoder_01_AttentionProj       = output_list[7]\n",
    "Decoder_01_SecondNormalization = output_list[9]\n",
    "Decoder_01_FirstLayerNN        = output_list[11]\n",
    "Decoder_01_SecondLayerNN       = output_list[13]  'Delta space'\n",
    "Decoder_01_final_output        = output_list[15]  'Residual + Delta space'\n",
    "'''\n",
    "module_name = [\"FirstNormalization\", \"QKV_representation\", \"AttentionHeads\", \"AttentionProj\", \"SecondNormalization\", \"FirstLayerNN\", \"SecondLayerNN\", \"Decoder_Final_Output\"]\n",
    "# Create Decoder_mask and flatten it\n",
    "Decoder_mask = np.concatenate([index_list + i*13 for i in range(12)])\n",
    "\n",
    "# Assuming output_list is already defined, we can proceed\n",
    "# Extract elements for Decoder_list\n",
    "Decoder_list = [output_list[mask] for mask in Decoder_mask]\n",
    "\n",
    "PositionalEmbedding = output_list[2]\n",
    "\n",
    "Decoder_list = [output_list[mask] for mask in Decoder_mask]\n",
    "\n",
    "for i in range(12):\n",
    "    for j in range(8):\n",
    "        print(\"Decoder \", i + 1 , \" \", module_name[j])\n",
    "        torch.save(Decoder_list[j+i*8], \"output_Captain/decoder/decoder_\"+str(i+1) +\"/\"+module_name[j]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cbb89c-7407-46f0-b15d-7f96bc6d06aa",
   "metadata": {},
   "source": [
    "Let's extract also the intermediate result of Output Attention + Residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda41f71-1b52-4d84-9c04-b1083f185e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract also Output Attention + Residual connection\n",
    "SecondLayerNN_list         =  [torch.load(f\"output_Captain/decoder/decoder_{i+1}/SecondLayerNN.pt\")[0] for i in range(12)]\n",
    "Decoder_Final_Output_list  =  [torch.load(f\"output_Captain/decoder/decoder_{i+1}/Decoder_Final_Output.pt\")[0][0] for i in range(12)]\n",
    "\n",
    "AttentionPlusResidual_list =  [DecOut - SecLayer  for DecOut, SecLayer in zip(Decoder_Final_Output_list, SecondLayerNN_list)]\n",
    "\n",
    "for i, AttentionPlusResidual in enumerate(AttentionPlusResidual_list):\n",
    "    torch.save((AttentionPlusResidual.unsqueeze(0),)\n",
    ", f\"output_Captain/decoder/decoder_{i+1}/AttentionPlusResidual.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be27576-5875-4f73-98f9-53653c3f4d7c",
   "metadata": {},
   "source": [
    "Push Back the last token to the language domain to study the evolution of the probability distribution during the 12 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679eefc7-86a9-4d34-b99a-068363dd3fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder 1\n",
      "    Top10 attn:  tensor([ 383,  198,  317,  314, 2448,  554,  632,  843, 1081, 1649]) tensor([0.0799, 0.0761, 0.0451, 0.0286, 0.0252, 0.0192, 0.0190, 0.0171, 0.0164,\n",
      "        0.0158], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([ 383,  198,  632,  843,  887, 1081, 1002,  554, 1318, 1649]) tensor([0.1186, 0.1049, 0.0713, 0.0696, 0.0537, 0.0327, 0.0299, 0.0293, 0.0271,\n",
      "        0.0267], grad_fn=<TopkBackward0>)\n",
      "Decoder 2\n",
      "    Top10 attn:  tensor([ 383,  198,  843,  632,  887, 1649, 1081, 1002, 1318,  554]) tensor([0.0966, 0.0772, 0.0644, 0.0564, 0.0532, 0.0361, 0.0316, 0.0299, 0.0293,\n",
      "        0.0236], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([ 632,  383,  198, 1002, 1649, 1318,  843,  887,  770, 1081]) tensor([0.0903, 0.0777, 0.0605, 0.0564, 0.0516, 0.0500, 0.0481, 0.0360, 0.0333,\n",
      "        0.0257], grad_fn=<TopkBackward0>)\n",
      "Decoder 3\n",
      "    Top10 attn:  tensor([ 632,  198,  383, 1002, 1649,  843,  887, 1318,  770,  775]) tensor([0.0828, 0.0588, 0.0557, 0.0544, 0.0540, 0.0526, 0.0512, 0.0407, 0.0257,\n",
      "        0.0233], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([ 632,  887,  383, 1002,  198, 1649,  843, 1318,  770, 1119]) tensor([0.1213, 0.0693, 0.0662, 0.0660, 0.0539, 0.0459, 0.0435, 0.0418, 0.0286,\n",
      "        0.0244], grad_fn=<TopkBackward0>)\n",
      "Decoder 4\n",
      "    Top10 attn:  tensor([ 843,  632,  198,  887, 1002,  383,  775, 1649, 1318,  314]) tensor([0.1017, 0.0844, 0.0838, 0.0560, 0.0491, 0.0452, 0.0364, 0.0350, 0.0309,\n",
      "        0.0281], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([ 632,  198, 1649,  383,  843, 1002,  887, 1318,  775,  314]) tensor([0.1100, 0.0930, 0.0767, 0.0741, 0.0627, 0.0556, 0.0455, 0.0436, 0.0347,\n",
      "        0.0296], grad_fn=<TopkBackward0>)\n",
      "Decoder 5\n",
      "    Top10 attn:  tensor([ 198,  632,  775, 1002,  843,  383, 1649,  887, 1318,  314]) tensor([0.1492, 0.0882, 0.0674, 0.0659, 0.0518, 0.0494, 0.0410, 0.0333, 0.0315,\n",
      "        0.0240], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([ 632,  198,  887, 1002,  775,  843,  383, 1629, 1649, 1318]) tensor([0.0922, 0.0862, 0.0685, 0.0675, 0.0656, 0.0605, 0.0581, 0.0457, 0.0375,\n",
      "        0.0353], grad_fn=<TopkBackward0>)\n",
      "Decoder 6\n",
      "    Top10 attn:  tensor([  198, 50256,   628,   632,  2750,   887,   843,  1002,   775,  1649]) tensor([0.6738, 0.1206, 0.1183, 0.0121, 0.0077, 0.0075, 0.0068, 0.0058, 0.0045,\n",
      "        0.0039], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([  198, 50256,   628,   887,   632,   843,  1649,  1002,  2750,   383]) tensor([0.6063, 0.0938, 0.0732, 0.0334, 0.0308, 0.0282, 0.0127, 0.0120, 0.0108,\n",
      "        0.0070], grad_fn=<TopkBackward0>)\n",
      "Decoder 7\n",
      "    Top10 attn:  tensor([  198, 50256,   628,   887,   843,   632,  1318,  1649,   775,   770]) tensor([0.6151, 0.1329, 0.0546, 0.0232, 0.0204, 0.0153, 0.0108, 0.0106, 0.0095,\n",
      "        0.0094], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([  198, 50256,   628,   843,   887,  1649,   632,   770,  1002,   775]) tensor([0.5264, 0.3424, 0.1141, 0.0022, 0.0019, 0.0013, 0.0012, 0.0011, 0.0009,\n",
      "        0.0007], grad_fn=<TopkBackward0>)\n",
      "Decoder 8\n",
      "    Top10 attn:  tensor([  198, 50256,   628,   843,   770,  6521,   632,   887,  1649,  1318]) tensor([8.5609e-01, 1.0521e-01, 3.3824e-02, 7.1409e-04, 4.4675e-04, 3.9199e-04,\n",
      "        3.0806e-04, 2.9714e-04, 2.2199e-04, 2.1355e-04],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([  198, 50256,   628,   843,   770,  6521,  1318,  2735,   887,  4222]) tensor([8.8174e-01, 7.1262e-02, 3.2712e-02, 2.3009e-03, 1.2920e-03, 1.2772e-03,\n",
      "        1.0330e-03, 9.0400e-04, 8.6831e-04, 6.7641e-04],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "Decoder 9\n",
      "    Top10 attn:  tensor([  198, 50256,   628,   770,  6521,   843,  2735,  4222,  1318,  1320]) tensor([9.2675e-01, 5.2569e-02, 1.2329e-02, 1.6195e-03, 8.4722e-04, 6.1939e-04,\n",
      "        6.1806e-04, 5.5860e-04, 4.7820e-04, 2.7312e-04],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([  198, 50256,   628,   843,  6521,   770,  2735,  1318,  4222,   887]) tensor([9.3929e-01, 4.3447e-02, 1.5719e-02, 2.9752e-04, 1.9351e-04, 1.4938e-04,\n",
      "        1.3593e-04, 1.1213e-04, 7.0532e-05, 6.9053e-05],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "Decoder 10\n",
      "    Top10 attn:  tensor([  198, 50256,   628,   843,   770,  6521,  2735,  3423,  4222,  6350]) tensor([9.7624e-01, 2.1326e-02, 1.9418e-03, 1.0505e-04, 5.4276e-05, 4.5797e-05,\n",
      "        3.6413e-05, 3.6038e-05, 3.0512e-05, 2.1996e-05],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([  198, 50256,   628,   843,  4222,   770,  3914,  2735,  6521,  3423]) tensor([9.4679e-01, 4.6284e-02, 6.7215e-03, 3.9394e-05, 2.4761e-05, 2.1871e-05,\n",
      "        1.5596e-05, 1.2938e-05, 1.1686e-05, 9.4193e-06],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "Decoder 11\n",
      "    Top10 attn:  tensor([  198, 50256,   628,   843,   440,  2011,  2735,   770,  3423,  3966]) tensor([9.5942e-01, 2.4345e-02, 1.3250e-02, 4.9387e-04, 3.4041e-04, 3.1307e-04,\n",
      "        1.7015e-04, 1.6015e-04, 1.3740e-04, 1.1968e-04],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([  198,   628, 50256,  2011,   440,   843,  7911,   314,  3966,   770]) tensor([9.6849e-01, 1.6627e-02, 1.1680e-02, 9.4757e-04, 3.7934e-04, 3.0403e-04,\n",
      "        2.0526e-04, 1.6106e-04, 1.5799e-04, 1.4392e-04],\n",
      "       grad_fn=<TopkBackward0>)\n",
      "Decoder 12\n",
      "    Top10 attn:  tensor([  198,   440,   628, 50256,   314,  2011,   447,   843,   383,   770]) tensor([0.8416, 0.0270, 0.0208, 0.0106, 0.0088, 0.0058, 0.0048, 0.0036, 0.0028,\n",
      "        0.0022], grad_fn=<TopkBackward0>)\n",
      "     Top10 dec:  tensor([  198,   440,   628,   314,  2011, 50256,   447,   383,   843,  3966]) tensor([0.7536, 0.0469, 0.0256, 0.0115, 0.0100, 0.0082, 0.0058, 0.0056, 0.0050,\n",
      "        0.0037], grad_fn=<TopkBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Extract the final normalization layer and the 'inverse matrix'\n",
    "ln_f = gpt2_model.ln_f\n",
    "lm_head = model.lm_head\n",
    "\n",
    "# Let's save the 'projection' on the vocabulary before and after the softmax\n",
    "for i, (out_attention, out_decoder) in enumerate(zip(AttentionPlusResidual_list, Decoder_Final_Output_list)):\n",
    "    print(f\"Decoder {i+1}\")\n",
    "    \n",
    "    final_norm = ln_f(out_attention)\n",
    "    projection = lm_head(final_norm[-1])\n",
    "    softmax = F.softmax(projection, dim=-1)\n",
    "    \n",
    "    top_values, top_indices = torch.topk(softmax, 10, dim=-1)\n",
    "\n",
    "    print(\"    Top10 attn: \", top_indices, top_values)\n",
    "\n",
    "    torch.save(projection, f\"output_Captain/last_token_pdf/decoder_{i+1}/attention_projection.pt\")\n",
    "    torch.save(softmax, f\"output_Captain/last_token_pdf/decoder_{i+1}/attention_softmax.pt\")\n",
    "\n",
    "    final_norm = ln_f(out_decoder)\n",
    "    projection = lm_head(final_norm[-1])\n",
    "    softmax = F.softmax(projection, dim=-1)\n",
    "\n",
    "    torch.save(projection, f\"output_Captain/last_token_pdf/decoder_{i+1}/out_decoder_projection.pt\")\n",
    "    torch.save(softmax, f\"output_Captain/last_token_pdf/decoder_{i+1}/out_decoder_softmax.pt\")\n",
    "    \n",
    "    # Extract the top 10 entries with highest softmax values\n",
    "    top_values, top_indices = torch.topk(softmax, 10, dim=-1)\n",
    "    print(\"     Top10 dec: \", top_indices, top_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2865ad51-cc5b-45fa-8b02-6077e50149f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
